\chapter{Related Work} \label{chap:rw}
This chapter introduces related work in the relevant fields of computer science and biological modeling.
I begin by examining work in the field of building metabolic models using flux balance analysis.
Next, I present a collection of automatic reduction systems for metabolic models, none of which have been applied to modeling cell-free systems.
I then examine what types of models have been used to model cell-free systems.
Finally, I investigate recent work on using variational autoencoders in biology and applying correlation loss terms to \glspl{vae}.

\section{Flux Balance Analysis}
Early metabolic models in the 1980s pioneered the use of stoichiometric equations to describe a biological system and predict the yield of a specific product~\cite{papoutsakis1984equations}.
These models soon adopted the use of Linear Programming (\gls{lp}) to solve for the optimal result~\cite{fell1986fat}.
After the transition to \gls{lp} solvers, this field was referred to as constraint-based analysis, while the primary technique used to solve these equations was called \gls{fba}.
These techniques were soon applied to describe the main metabolic systems in \gls{ecoli}~\cite{majewski1990simple}.
Importantly, \gls{fba} has repeatedly been shown to predict phenotypes that corresponded to real-world data~\cite{varma1994stoichiometric, edwards2001silico, segre2002analysis, bordbar2014constraint}.

Improvements on these early models have primarily focused on the addition of new genes, metabolites, and reactions~\cite{varma1993metabolic}.
After the first \gls{ecoli} genome was sequenced and annotated, the size of these models grew rapidly.
The earliest genome scale model (\gls{gem}) for \gls{ecoli} was iJE660a, a model that described 627 unique reactions in a typical \gls{ecoli} cell~\cite{edwards2000escherichia}.
Over the years, more and more reactions have been progressively added to the model to better describe the biology.
This work uses the most recent \gls{ecoli} \gls{gem}, iJO1366 from 2011, which contains 2583 reactions~\cite{orth2011comprehensive}.
Since 2011, work in this field has primarily focused on extending metabolic models to incorporate other types of biological information.
For instance, recent work has involved the addition of gene expression data to create \glspl{me}~\cite{lloyd2017cobrame}.
This has drastically increased the dimensionality and complexity of the model: the most recent \gls{me}, iJL1678-ME has 79871 reactions.

\section{Reduction of metabolic models}
As these \glspl{gem} begin to incorporate even more information, the models begin to suffer from the curse of dimensionality~\cite{bellman2013dynamic}.
%One issue with using a full \gls{gem} is the extremely high dimensionality due to the fact that every reaction occurring in a cell is detailed.
To deal with this issue, a number of papers have tried to reduce these genome scale models to their most essential reactions.
The Hatzimanikatis lab has developed multiple tools to reduce the dimensionality of these models.
redGEM finds core metabolic models by performing a graph search where the objective is to minimize information loss~\cite{ataman2017redgem}.
lumpGEM also uses graph search techniques to identify and collapses entire reaction networks into a single balanced reaction~\cite{ataman2017lumpgem}.
Other important tools in this area are NetworkReducer and minNW.
NetworkReducer iteratively prunes and compresses reaction networks while maintaining a set of protected reactions until a core model is found~\cite{erdrich2015algorithm}.
minNW uses \gls{milp} techniques to compute minimal subnetworks with certain constraints~\cite{rohl2017mixed}.
All of these techniques reduce the dimensionality of a full \gls{gem} to a simpler representation of the system.

The methods above use some sort of search technique to find minimal core models from a stoichiometric description of the entire system.
However, there has also been work that uses general dimensionality reduction techniques such as \gls{pca}.
This idea has been incorporated into a reduction technique called \gls{pema}~\cite{von2016principal}.
\gls{pema} identifies subnetworks that maximize the observed variance similar to how the principal components of \gls{pca} work.
A more recent method called ``Principal metabolic flux mode analysis" explicitly incorporates \gls{pca} and \gls{fba}~\cite{bhadra2017principal}.
It reduces the dimensionality of the system by running a form of \gls{pca} on the stoichiometric matrix that is regularized by the steady state assumption from \gls{fba}.

%TODO: add reference to https://www.cell.com/cell-systems/pdf/S2405-4712(17)30010-8.pdf
% CITE Network-based analysis of metabolic regulation in the human red blood cell
% CITE  new constraint-based description of the steady-state flux cone of metabolic networks
%Bayesian \gls{fba}
%Network models on \gls{fba}

This work differs from these earlier reduction techniques in a few ways.
Prior work so far has been constrained to looking at linear techniques of dimensionality reduction.
Many biological relationships are non-linear, so there are limits to how well linear models can perform.
I approach the problem of reducing metabolic models differently by using nonlinear techniques and deep learning.
In addition, the techniques above all deal with the stoichiometric matrix of the system without using real experimental data.
Finally, none of the techniques above have specifically targeted building models for \gls{cfps} systems.

\section{Modeling cell-free systems}\label{rw:mod-cf}
Models of cell-free systems have typically been based on kinetic models of transcription and translation.
These models are often quite good at predicting the time-course of protein production, but they have a very narrow focus.
Transcription and translation reactions can be described using differential equations when the rate constant of the reaction is known.
This type of kinetic model has been applied to the commercial \gls{ecoli} cell-free system TXTL, and was able to accurately describe the dynamics of their gene circuit of interest~\cite{tuza2013silico}.
Other work has proposed a more general framework for modeling metabolic networks in cell-free systems using these types of kinetic models~\cite{wayman2015dynamic}.
One issue with these types of kinetic models is that only reactions with known rate constants can be modeled accurately.
Recent work attempts to solve that problem using Bayesian parameter inference to infer the kinetic parameters for these reactions~\cite{moore2018rapid}.

There have only been a few attempts to use constraint-based metabolic models and \gls{fba} to model cell-free systems.
One model adapted a full-scale \gls{ecoli} \gls{fba} model to a cell-free system by hand~\cite{bujara2012silico}.
The authors decided which parts of the full model were relevant for cell-free systems and then removed any irrelevant reactions from the model.
A more recent attempt took a bottom-up approach to building a \gls{fba} model for cell-free systems~\cite{vilkhovoy2017sequence}.
Instead of removing reactions from the full \gls{ecoli} \gls{gem} until they had a cell-free model, the authors instead selected the reactions they believed to be most important for protein synthesis.
Since protein synthesis is the main goal of \gls{cfps} systems, they were able to use these reactions to build an accurate cell-free \gls{fba} model.
These models show that it is possible to use \gls{fba} to describe cell-free systems.
However, neither approach is able to construct cell-free systems in a systematic way that could scale to other labs or other organisms.

%Hybrid agent-based model for quantitative in-silico cell-free protein synthesis. 2016
%https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5288458/

\section{Variational autoencoders}
Autoencoders have been around for many years, but \glspl{vae} were first introduced in 2013~\cite{kingma2013auto, rezende2014stochastic}.
Since their introduction, \glspl{vae} have been used for everything from transferring image features~\cite{larsen2015autoencoding} to molecule generation~\cite{gomez2016automatic}.
%Due to their ability to function as generative networks, much of the work in the field has focused on applying \glspl{vae} to generate synthetic images.
\glspl{ae}, and \glspl{vae} in particular, have only just begun making their way into analyzing biological data.
The typical dimensionality reduction technique in biology is \gls{pca}~\cite{ringner2008principal}.
However, recent work has begun to explore the uses of \glspl{vae} on biological data.
One study examined cancer transcriptomics data using a \gls{vae} to extract meaningful features of cancer gene expression~\cite{way2017extracting}.
Another work showed that a \gls{vae} was able to separate tissue types based on mass spectrometry data \cite{inglese2017variational}.
These papers have used the original structure and loss function for their \glspl{vae}, but there have also been development of new types of \glspl{vae}.

%Also introduced by ~\cite{rezende2014stochastic}
Specifically, work has also been done to incorporate correlation loss terms with \glspl{ae}.
Correlation Neural Networks were first introduced as a way to make \glspl{ae} more effective on multi-modal data such as labeled images~\cite{chandar2016correlational}.
By maximizing the correlation between the latent representations for each view of the data, the authors were able to improve performance.
This idea has been expanded in Relational Neural Networks, which also looks at correlation within the data to affect the \gls{ae} loss term~\cite{meng2017relational}.
All of these papers use correlations within the dataset or latent representation of the \gls{ae}.
I introduce a new type of \gls{vae}, Corr-VAE, which uses a correlation loss term with respect to external experimental data.