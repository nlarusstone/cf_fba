{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/fluxes_ecoli_biomass.npy')\n",
    "data_no_nan = np.nan_to_num(x=data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = np.reshape(data_no_nan, (data.shape[0] * data.shape[1], data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(range(41) * data.shape[0])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "train_ind = np.random.choice(flat_data.shape[0], size=int(0.9 * flat_data.shape[0]), replace=False)\n",
    "test_ind = list(set(range(flat_data.shape[0])) - set(train_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = flat_data[train_ind], y[train_ind]\n",
    "X_test, y_test = flat_data[test_ind], y[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ae(X_shape):\n",
    "    encoding_sz = 100\n",
    "    input_lay = Input(shape=(X_shape,))\n",
    "    encoded = Dense(2 * encoding_sz, activation='relu')(input_lay)\n",
    "    encoded = Dense(encoding_sz, activation='relu')(encoded)\n",
    "\n",
    "    decoded = Dense(2 * encoding_sz, activation='relu')(encoded)\n",
    "    decoded = Dense(X_shape, activation='sigmoid')(decoded)\n",
    "    \n",
    "    ae = Model(input_lay, decoded)\n",
    "    encoder = Model(input_lay, encoded)\n",
    "    encoded_input = Input(shape=(2 * encoding_sz,))\n",
    "    decoder_layer = ae.layers[-1]\n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "    \n",
    "    ae.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "    return ae, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder, decoder = build_ae(X_train.shape[1])\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "encoded_fluxes = encoder.predict(X_test)\n",
    "decoded_fluxes = decoder.predict(encoded_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(X_train)\n",
    "max_val = np.max(X_train)\n",
    "scale = lambda x: (x + min_val) / max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = scale(X_train)\n",
    "X_test_scale = scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim1 = 512\n",
    "encoded_sz = 256\n",
    "latent_dim = 2\n",
    "epsilon_std = 1.0\n",
    "X_shape = 2500\n",
    "# Encoder network\n",
    "x = Input(shape=(X_shape,))\n",
    "h = Dense(encoded_dim1, activation='relu')(x)\n",
    "h = Dense(encoded_sz, activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "# Sample points from latent space\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_h = Dense(encoded_sz, activation='relu')\n",
    "decoder_h2 = Dense(encoded_dim1, activation='relu')\n",
    "decoder_mean = Dense(X_shape, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "h_decoded2 = decoder_h2(h_decoded)\n",
    "x_decoded_mean = decoder_mean(h_decoded2)\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "xent_loss = X_shape * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print xent_loss\n",
    "print kl_loss\n",
    "print vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "\n",
    "def build_vae(X_shape, batch_size=100):\n",
    "    encoded_dim1 = 512\n",
    "    encoded_sz = 256\n",
    "    # Encoder network\n",
    "    x = Input(shape=(X_shape,))\n",
    "    h = Dense(encoded_dim1, activation='relu')(x)\n",
    "    h = Dense(encoded_sz, activation='relu')(h)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "    \n",
    "    # Sample points from latent space\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    \n",
    "    # Decoder network\n",
    "    decoder_h = Dense(encoded_sz, activation='relu')\n",
    "    decoder_h2 = Dense(encoded_dim1, activation='relu')\n",
    "    decoder_mean = Dense(X_shape, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    h_decoded2 = decoder_h2(h_decoded)\n",
    "    x_decoded_mean = decoder_mean(h_decoded2)\n",
    "\n",
    "    # end-to-end autoencoder\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "    \n",
    "    xent_loss = X_shape * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='rmsprop')\n",
    "    #vae.summary()\n",
    "\n",
    "    # encoder, from inputs to latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # generator, from latent space to reconstructed inputs\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    _h_decoded = decoder_h(decoder_input)\n",
    "    _h_decoded2 = decoder_h2(_h_decoded)\n",
    "    _x_decoded_mean = decoder_mean(_h_decoded2)\n",
    "    generator = Model(decoder_input, _x_decoded_mean)\n",
    "    return vae, encoder, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%debug\n",
    "latent_dim = 2\n",
    "batch_size = 256\n",
    "epsilon_std = 1.0\n",
    "vae, encoder, generator = build_vae(X_scale.shape[1], batch_size)\n",
    "es = EarlyStopping(patience=2)\n",
    "vae.fit(X_scale,\n",
    "        shuffle=True,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_scale, None),\n",
    "        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(X_test_scale, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rct(df, rct, y_test):\n",
    "    y_new = []\n",
    "    for ind in y_test:\n",
    "        y_new.append(df[rct][ind])\n",
    "    return y_new\n",
    "get_rct(df, 'Glucose', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm1 = cm.get_cmap('tab20b', 20)\n",
    "#cm2 = cm.get_cmap('tab20c', 20)\n",
    "cmap = cm.get_cmap('plasma', 41)\n",
    "#cmap = lambda x: cm1(x) if x < 21 else cm2(x)\n",
    "xmin, xmax = np.amin(x_test_encoded[:, 0]), np.amax(x_test_encoded[:, 0])\n",
    "ymin, ymax = np.amin(x_test_encoded[:, 1]), np.amax(x_test_encoded[:, 1])\n",
    "x_diff = (xmax - xmin) / 2.0\n",
    "y_diff = (ymax - ymin) / 2.0\n",
    "for col in df.columns[4:]:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=get_rct(df, col, y_test), cmap=cmap)\n",
    "    plt.xlim((xmin - x_diff, xmax + x_diff))\n",
    "    plt.ylim((ymin - y_diff, ymax + y_diff))\n",
    "    plt.title(col)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap=cmap)\n",
    "plt.xlim((xmin - x_diff, xmax + x_diff))\n",
    "plt.ylim((ymin - y_diff, ymax + y_diff))\n",
    "plt.title('Variant')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Karim_MetEng_2018_Figure2_Data.csv')\n",
    "df.drop(columns=['Area_1', 'Area_2', 'Conc_1', 'Conc_2'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
