{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import cobra\n",
    "import cobra.test\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "if not '/Users/nlarusstone/Documents/MPhil/Research/cf_fba' in sys.path:\n",
    "    sys.path.append('/Users/nlarusstone/Documents/MPhil/Research/cf_fba')\n",
    "import src.utils as utils\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = cobra.io.load_json_model(filename='../models/ecoli_but.json')\n",
    "model = cobra.io.read_sbml_model('../models/ecoli_cf_base.sbml')\n",
    "#model = cobra.io.read_sbml_model('../models/iJO1366.xml')\n",
    "mod_cf = model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "      <th>STD</th>\n",
       "      <th>AVG.1</th>\n",
       "      <th>STD.1</th>\n",
       "      <th>Mg(Glu)2</th>\n",
       "      <th>NH4(Glu)</th>\n",
       "      <th>K(Glu)</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>K2HPO4</th>\n",
       "      <th>NAD</th>\n",
       "      <th>ATP</th>\n",
       "      <th>CoA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.21</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG  STD  AVG.1  STD.1  Mg(Glu)2  NH4(Glu)  K(Glu)  Glucose  K2HPO4  NAD  \\\n",
       "0  0.00  0.0   0.00   0.00       8.0      10.0     134        0      10  0.5   \n",
       "1  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.0   \n",
       "2  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.5   \n",
       "3  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.5   \n",
       "4  1.21  1.7   0.09   0.13       8.0      10.0     134      200      10  0.5   \n",
       "\n",
       "   ATP  CoA  \n",
       "0  0.0  0.5  \n",
       "1  0.0  0.5  \n",
       "2  0.0  2.0  \n",
       "3  0.0  1.6  \n",
       "4  2.0  0.5  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Karim_MetEng_2018_Figure2_Data.csv')\n",
    "df.drop(columns=['Area_1', 'Area_2', 'Conc_1', 'Conc_2'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look into GoalEnv\n",
    "class FBA_Env(gym.Env):      \n",
    "    def __init__(self, model, df):\n",
    "        self.model = model.copy()\n",
    "        self.cur_model = self.model.copy()\n",
    "        self.rxns = model.reactions\n",
    "        self.n_rxns = len(self.rxns)\n",
    "        # TODO Add metabs\n",
    "        self.metabs = model.metabolites\n",
    "        n_metabs = len(self.metabs)\n",
    "        # LEARNING FROM EXPERIMENTAL DATA:\n",
    "        self.df = df\n",
    "        self.cond_scores = df['AVG.1']\n",
    "        # Add 1 for not removing any\n",
    "        self.action_space = spaces.Discrete(self.n_rxns) # TODO: Think about using MultiBinary\n",
    "        self.action_types = ('remove', 'add')\n",
    "        #spaces.Dict({\"reaction\": spaces.Discrete(n_rxns + 1), \"metabolite\": spaces.Discrete(n_metabs + 1)})\n",
    "        # Whether or not a reaction is present\n",
    "        self.observation_space = spaces.MultiBinary(self.n_rxns)\n",
    "        # In case they forget to reset\n",
    "        self.state = np.ones(self.n_rxns, dtype=np.int8)\n",
    "        self.time = 0\n",
    "        \n",
    "        self.unique_fluxes = {}\n",
    "        \n",
    "        self.log = []\n",
    "        \n",
    "        self._seed()\n",
    "        #spaces.Dict({\"reaction\": spaces.Discrete(2), \"metabolite\": spaces.Discrete(3)})\n",
    "        \n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.state\n",
    "    \n",
    "    def _take_action(self, state, action):\n",
    "        # Returns new state\n",
    "        return NotImplemented\n",
    "    \n",
    "    def _evaluate(self, state_rxns):\n",
    "        return NotImplemented\n",
    "    \n",
    "    def reset(self):\n",
    "        # TODO, choose random starting state\n",
    "        self.state = np.ones(self.n_rxns, dtype=np.int8)\n",
    "        self.cur_model = self.model.copy()\n",
    "        self.last_action = None\n",
    "        self.time = 0\n",
    "        \n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self,action):\n",
    "        # TODO: do better than this?\n",
    "        new_state = self._take_action(self.state, action)\n",
    "        self.state = new_state\n",
    "        reward = self._evaluate(self.state)\n",
    "\n",
    "        done = False\n",
    "        #if self.time > 300:\n",
    "        #    done = True\n",
    "\n",
    "        self.time += 1\n",
    "            \n",
    "        return self.rxns[action[0]], reward, done, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look into GoalEnv\n",
    "class FBA_Step_Env(FBA_Env):  \n",
    "    def _take_action(self, state, act):\n",
    "        action, action_type = act\n",
    "        if action_type == 'add':\n",
    "            state[action] = 1\n",
    "            rxn = self.rxns[action]\n",
    "            self.cur_model.add_reaction(rxn)\n",
    "        else:\n",
    "        # Returns new state\n",
    "            state[action] = 0\n",
    "            rxn = self.rxns[action]\n",
    "            if rxn in self.cur_model.reactions:\n",
    "                self.cur_model.reactions.get_by_id(rxn.id).remove_from_model()\n",
    "            else:\n",
    "                self.log.append(('rxn {0} not in model with state {1}'.format(rxn, self.state)))\n",
    "        return state\n",
    "    \n",
    "    def _evaluate(self, state_rxns):\n",
    "        objs = utils.add_addl_reactants(self.cur_model, self.df)\n",
    "        if not tuple(objs) in self.unique_fluxes:\n",
    "            self.unique_fluxes[tuple(objs)] = state_rxns\n",
    "        if sum(objs) < 0.01:\n",
    "            return -1000\n",
    "        corr = scipy.stats.spearmanr(objs, self.cond_scores)\n",
    "        return corr\n",
    "    \n",
    "    def _evaluate_fluxes(self, state_rxns):\n",
    "        #objs = utils.add_addl_reactants(self.cur_model, self.df)\n",
    "        objs, fluxes = utils.gen_fluxes_addl_reactants(self.cur_model, self.df)\n",
    "        if not tuple(objs) in self.unique_fluxes:\n",
    "            self.unique_fluxes[tuple(objs)] = (fluxes, state_rxns)\n",
    "        if sum(objs) < 0.01:\n",
    "            return -1000\n",
    "        corr = scipy.stats.spearmanr(objs, self.cond_scores)\n",
    "        return corr\n",
    "    \n",
    "    def _evaluate_flux(self, state_rxns):\n",
    "        #objs = utils.add_addl_reactants(self.cur_model, self.df)\n",
    "        obj, fluxes = utils.gen_fluxes(self.cur_model)\n",
    "        if not tuple(fluxes) in self.unique_fluxes:\n",
    "            self.unique_fluxes[tuple(fluxes)] = state_rxns\n",
    "        if obj < 10 ** -7:\n",
    "            return -1000\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation, reward, done, prev_action):\n",
    "        return (self.action_space.sample(), 'remove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBackAgent(object):\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation, reward, done, prev_action):\n",
    "        if reward < -1:\n",
    "            return (prev_action[0], 'add')\n",
    "        return (self.action_space.sample(), 'remove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.flux_analysis.deletion import single_reaction_deletion\n",
    "with mod_cf as model:\n",
    "    print len(model.reactions)\n",
    "    dels = single_reaction_deletion(model=model)\n",
    "    #double_reaction_deletion\n",
    "    #processes = 4\n",
    "    print len(model.reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Time 0, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 10, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 20, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 30, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 40, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 50, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 60, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 70, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 80, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 90, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 100, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 110, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 120, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 130, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 140, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Episode 1\n",
      "Time 0, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 10, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 20, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 30, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 40, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 50, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 60, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 70, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 80, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 90, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 100, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 110, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 120, reward: SpearmanrResult(correlation=-0.19183847927058997, pvalue=0.22952747856384234)\n",
      "Time 130, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 140, reward: SpearmanrResult(correlation=-0.11898505817545255, pvalue=0.45872188085479504)\n",
      "Time 150, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 160, reward: SpearmanrResult(correlation=-0.16572293526721518, pvalue=0.3004306847707215)\n",
      "Time 170, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 180, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 190, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 200, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 210, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 220, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Episode 2\n",
      "Time 0, reward: SpearmanrResult(correlation=-0.17550469962430487, pvalue=0.27239169559356013)\n",
      "Time 10, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 20, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 30, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 40, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 50, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 60, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n",
      "Time 70, reward: SpearmanrResult(correlation=-0.09438894300109013, pvalue=0.5571994263547196)\n"
     ]
    }
   ],
   "source": [
    "env = FBA_Step_Env(mod_cf, df)\n",
    "agent = AddBackAgent(env.action_space)\n",
    "max_reward = (0, None)\n",
    "prev_action, done = None, False\n",
    "for i_episode in range(10):\n",
    "    print 'Episode {0}'.format(i_episode)\n",
    "    observation = env.reset()\n",
    "    reward = 0\n",
    "    for t in range(501):\n",
    "        #env.render()\n",
    "        #print(observation)\n",
    "        action = agent.act(observation, reward, done, prev_action)\n",
    "        observation, reward, done, prev_action = env.step(action)\n",
    "        if np.isnan(reward).any():\n",
    "            print 'NAN'\n",
    "            break\n",
    "        if t % 10 == 0:\n",
    "            print 'Time {0}, reward: {1}'.format(t, reward)\n",
    "        if reward > max_reward[0]:\n",
    "            max_reward = (reward, observation)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "print max_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_rxns = []\n",
    "i = 0\n",
    "for objs, rxns in env.unique_fluxes.items():\n",
    "    i += 1\n",
    "    if sum(objs) < 0.01:\n",
    "        continue\n",
    "    dis_rxns.append(rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print i\n",
    "print len(dis_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = (0, None)\n",
    "for rxn in range(len(dis_rxns)):\n",
    "    for flux_ser in dis_rxns[rxn][0]:\n",
    "        if flux_ser.shape[0] > max_len[0]:\n",
    "            max_len = (flux_ser.shape[0], flux_ser)\n",
    "ind = max_len[1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 41, 2638)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluxes = []\n",
    "for rxn in range(len(dis_rxns)):\n",
    "    experiments = []\n",
    "    for flux_ser in dis_rxns[rxn][0]:\n",
    "        flux_ser_pad = flux_ser.reindex(ind)\n",
    "        experiments.append(np.array(flux_ser_pad))\n",
    "    experiment = np.stack(experiments, axis=0)\n",
    "    fluxes.append(experiment)\n",
    "flux_arr = np.stack(fluxes, axis=0)\n",
    "flux_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux_arr[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/fluxes_ecoli_but', flux_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_arr_no_nan = np.nan_to_num(x=flux_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def viz_flux_std(flux_arr):\n",
    "stds = []\n",
    "for exp in flux_arr_no_nan:\n",
    "    for cond in exp:\n",
    "        stds.append(np.std(cond))\n",
    "#viz_flux_std(flux_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look into GoalEnv\n",
    "class FBA_Pathway_Env(FBA_Env):  \n",
    "    def _take_action(self, state, action):\n",
    "        # Returns new state\n",
    "        state[action] = 0\n",
    "        rxn = self.rxns[action]\n",
    "        self.cur_model.reactions.get_by_id(rxn.id).remove_from_model()\n",
    "        return state\n",
    "    \n",
    "    def _evaluate(self, state_rxns):\n",
    "        objs = utils.add_addl_reactants(self.cur_model, self.df)\n",
    "        #for start_cond_dict in self.starting_conds:\n",
    "        #    start_cond = start_cond_dict.keys()\n",
    "            # Update Model with starting condition\n",
    "       #     with self.cur_model as model:\n",
    "        #        model.add_reactions(start_cond)\n",
    "        #        objs.append(model.slim_optimize())\n",
    "        # Discourage infeasible solutions\n",
    "        if sum(objs) == 0:\n",
    "            return -1000\n",
    "        corr = scipy.stats.spearmanr(objs, self.cond_scores)\n",
    "        return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015069444444443763, 0.015069444444444038, 0.015069444444443357, 0.015069444444443357, 0.015069444444444705, 0.015069444444443865, 0.028958333333332198, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444444705, 0.015069444444443865, 0.02340277777777668, 0.015069444444443357, 0.015069444444443357, 0.015069444444444705, 0.015069444444443865, 0.015069444444444097, 0.015069444444443357, 0.015069444444443357, 0.01784722222222109, 0.015069444444443436, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444444522, 0.015069444444443357, 0.015069444444444323, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.0011805555555556254, 0.006736111111111482, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357, 0.015069444444443357]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.40796294739949274, pvalue=0.008102888644114212)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(mod, starting_conds, cond_scores):\n",
    "    model = mod.copy()\n",
    "    objs = []\n",
    "    for start_cond_dict in starting_conds:\n",
    "        start_cond = start_cond_dict.keys()\n",
    "        # Update Model with starting condition\n",
    "        with model as model:\n",
    "            model.add_reactions(start_cond)\n",
    "            objs.append(model.slim_optimize())\n",
    "    print objs\n",
    "    corr = scipy.stats.spearmanr(objs, cond_scores)\n",
    "    return corr\n",
    "test(mod_cf, rxn_conds, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01506944444444309, 0.015069444444442822, 0.015069444444443436, 0.015069444444443343, 0.015069444444444005, 0.015069444444443011, 0.028958333333331886, 0.015069444444444935, 0.015069444444444935, 0.015069444444444935, 0.015069444444447501, 0.015069444444447501, 0.015069444444444724, 0.015069444444444935, 0.02340277777777719, 0.015069444444444935, 0.015069444444444935, 0.015069444444444724, 0.015069444444447501, 0.015069444444444855, 0.015069444444444935, 0.015069444444444935, 0.017847222222222698, 0.015069444444444238, 0.015069444444444935, 0.015069444444447501, 0.015069444444447501, 0.015069444444441535, 0.015069444444444935, 0.015069444444444885, 0.015069444444447501, 0.015069444444447501, 0.015069444444444935, 0.015069444444444935, 0.015069444444447501, 0.0011805555555562995, 0.006736111111113903, 0.015069444444447501, 0.015069444444444935, 0.015069444444444935, 0.015069444444444935]\n",
      "SpearmanrResult(correlation=0.19192023893475982, pvalue=0.22932525346762614)\n"
     ]
    }
   ],
   "source": [
    "with mod_cf as model:\n",
    "    model.reactions.HSDy.remove_from_model()\n",
    "    model.reactions.UDPGPpp.remove_from_model()\n",
    "    print test(model, rxn_conds, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Learner:\n",
    "\n",
    "    def __init__(self, discount):\n",
    "        self.last_state  = None\n",
    "        self.last_action = None\n",
    "        self.last_reward = None\n",
    "        self.Q = {}\n",
    "        self.alphas = {}\n",
    "        self.epsilon = None # will be modified by loop\n",
    "        self.score = 0\n",
    "        self.discount = discount\n",
    "        self.raw_states = []\n",
    "        self.disc_states = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_state  = None\n",
    "        self.last_action = None\n",
    "        self.last_reward = None\n",
    "        self.score = 0\n",
    "\n",
    "    def disc_state(self, old_state):\n",
    "        old_bot_diff = old_state['tree']['bot'] - old_state['monkey']['bot']\n",
    "        new_bot_diff = (old_bot_diff + 333) / 100\n",
    "        new_bot_diff = max(0, new_bot_diff)\n",
    "        \n",
    "        old_tree_dist = old_state['tree']['dist']\n",
    "        new_tree_dist = (old_tree_dist + 115) / 120\n",
    "        new_tree_dist = max(0, new_tree_dist)\n",
    "\n",
    "        old_monk_vel = old_state['monkey']['vel']\n",
    "        new_monk_vel = (old_monk_vel + 40) / 20\n",
    "        new_monk_vel = max(0, new_monk_vel)\n",
    "\n",
    "        return (new_bot_diff, new_tree_dist, new_monk_vel)\n",
    "        \n",
    "        \n",
    "    def action_callback(self, state):\n",
    "        '''Implement this function to learn things and take actions.\n",
    "        Return 0 if you don't want to jump and 1 if you do.'''\n",
    "        \n",
    "        self.raw_states.append(state)\n",
    "        self.disc_states.append(self.disc_state(state))\n",
    "\n",
    "        if self.last_state is None:\n",
    "            self.last_state = state\n",
    "            self.last_action = 0\n",
    "            return 0\n",
    "\n",
    "        # self.states.append(state)\n",
    "        discount = self.discount\n",
    "\n",
    "        # UPDATE Q\n",
    "        last_state = self.disc_state(self.last_state)\n",
    "        cur_state = self.disc_state(state)\n",
    "        last_action = self.last_action\n",
    "        last_reward = self.last_reward\n",
    "        \n",
    "        if last_state not in self.Q:\n",
    "            self.Q[last_state] = [0., 0.]\n",
    "            self.alphas[last_state] = [1., 1.]\n",
    "        if cur_state not in self.Q:\n",
    "            self.Q[cur_state] = [0., 0.]\n",
    "            self.alphas[cur_state] = [1., 1.]\n",
    "\n",
    "        old_val = self.Q[last_state][last_action]\n",
    "        alpha = self.alphas[last_state][last_action]\n",
    "        self.Q[last_state][last_action] = old_val + (1./alpha)*(last_reward + discount*max(self.Q[cur_state]) - old_val)\n",
    "        self.alphas[last_state][last_action] += 1.\n",
    "        \n",
    "        # CHOOSE NEW ACTION\n",
    "        rnd = npr.random()\n",
    "\n",
    "        if rnd > self.epsilon:\n",
    "            # choose optimal action\n",
    "            action_vals = self.Q[cur_state]\n",
    "            new_action = 0 if action_vals[0] >= action_vals[1] else 1\n",
    "        else:\n",
    "            # act randomly, 0.7 prob of holding, 0.3 prob of jumping\n",
    "            rnd  = npr.random()\n",
    "            new_action = 0 if rnd < 0.8 else 1\n",
    "\n",
    "        self.last_action = new_action\n",
    "        self.last_state  = state\n",
    "        self.score = state['score']\n",
    "\n",
    "        return self.last_action\n",
    "\n",
    "    def reward_callback(self, reward):\n",
    "        '''This gets called so you can see what reward you get.'''\n",
    "        self.last_reward = reward\n",
    "\n",
    "\n",
    "if len(sys.argv) != 3:\n",
    "    print 'Usage: python QLearn.py numIters discountRate'\n",
    "    sys.exit(0)\n",
    "\n",
    "iters = int(sys.argv[1])\n",
    "discount = float(sys.argv[2])\n",
    "learner = Learner(discount)\n",
    "scores = []\n",
    "\n",
    "for ii in xrange(iters):\n",
    "\n",
    "    learner.epsilon = 1./(ii+1)\n",
    "\n",
    "    # Make a new monkey object.\n",
    "    swing = SwingyMonkey(sound=False,            # Don't play sounds.\n",
    "                         text=\"Epoch %d\" % (ii), # Display the epoch on screen.\n",
    "                         tick_length=1,          # Make game ticks super fast.\n",
    "                         action_callback=learner.action_callback,\n",
    "                         reward_callback=learner.reward_callback)\n",
    "    # Loop until you hit something.\n",
    "    while swing.game_loop():\n",
    "        pass\n",
    "    \n",
    "    scores.append(learner.score)\n",
    "\n",
    "    # Reset the state of the learner.\n",
    "    learner.reset()\n",
    "\n",
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.show()\n",
    "plt.plot(moving_average(scores))\n",
    "plt.show()\n",
    "plt.hist(scores)\n",
    "plt.show()\n",
    "print np.median(scores)\n",
    "print np.mean(scores)\n",
    "print max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look into GoalEnv\n",
    "class FBA_Env(gym.Env):      \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.rxns = model.reactions\n",
    "        self.n_rxns = len(self.rxns)\n",
    "        # TODO Add metabs\n",
    "        self.metabs = model.metabolites\n",
    "        n_metabs = len(self.metabs)\n",
    "        # Add 1 for not removing any\n",
    "        self.action_space = spaces.Discrete(n_rxns + 1) # TODO: Think about using MultiBinary\n",
    "        #spaces.Dict({\"reaction\": spaces.Discrete(n_rxns + 1), \"metabolite\": spaces.Discrete(n_metabs + 1)})\n",
    "        # Whether or not a reaction is present\n",
    "        self.observation_space = spaces.MultiBinary(n_rxns + 1)\n",
    "        self.state = self.observation_space.sample()\n",
    "        self.time = 0\n",
    "        \n",
    "        self._seed()\n",
    "        #spaces.Dict({\"reaction\": spaces.Discrete(2), \"metabolite\": spaces.Discrete(3)})\n",
    "\n",
    "    def _evaluate(self, state_rxns):\n",
    "        # 1 represents a reaction to keep, so remove if not 1\n",
    "        rxns_to_remove = [i for i,j in zip(self.rxns, state_rxns) if not j]\n",
    "        with self.model as model:\n",
    "            model.remove_reactions(rxns_to_remove)\n",
    "            obj = model.slim_optimize()\n",
    "        return obj\n",
    "        \n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    def step(self,action):\n",
    "        cur_rxns = self.state        \n",
    "        x = self.state\n",
    "        reward = self._evaluate(cur_rxns)\n",
    "        # TODO: do better than this?\n",
    "        new_rxns = self.observation_space.sample()\n",
    "        new_x = new_rxns\n",
    "\n",
    "        self.state = new_x\n",
    "\n",
    "        done = False\n",
    "        if self.time > 300:\n",
    "            done = True\n",
    "\n",
    "        self.time += 1\n",
    "            \n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # self.step(np.array([0,0,0,0]))[0]\n",
    "        # TODO, choose random starting state\n",
    "        self.state = np.ones(self.n_rxns, dtype=np.int8)\n",
    "        self.last_u = None\n",
    "        self.time = 0\n",
    "        \n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.state\n",
    "\n",
    "    #def get_params(self):\n",
    "    #    return self.A, self.B, self.Q, self.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "      <th>STD</th>\n",
       "      <th>AVG.1</th>\n",
       "      <th>STD.1</th>\n",
       "      <th>Mg(Glu)2</th>\n",
       "      <th>NH4(Glu)</th>\n",
       "      <th>K(Glu)</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>K2HPO4</th>\n",
       "      <th>NAD</th>\n",
       "      <th>ATP</th>\n",
       "      <th>CoA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.21</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG  STD  AVG.1  STD.1  Mg(Glu)2  NH4(Glu)  K(Glu)  Glucose  K2HPO4  NAD  \\\n",
       "0  0.00  0.0   0.00   0.00       8.0      10.0     134        0      10  0.5   \n",
       "1  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.0   \n",
       "2  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.5   \n",
       "3  0.00  0.0   0.00   0.00       8.0      10.0     134      200      10  0.5   \n",
       "4  1.21  1.7   0.09   0.13       8.0      10.0     134      200      10  0.5   \n",
       "\n",
       "   ATP  CoA  \n",
       "0  0.0  0.5  \n",
       "1  0.0  0.5  \n",
       "2  0.0  2.0  \n",
       "3  0.0  1.6  \n",
       "4  2.0  0.5  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
