{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.metrics import streaming_pearson_correlation\n",
    "from keras.models import load_model\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import maxabs_scale, minmax_scale, normalize, scale, robust_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "%load_ext autoreload\n",
    "import sys\n",
    "if not '/home/nlarusstone/cf_fba' in sys.path:\n",
    "    sys.path.append('/home/nlarusstone/cf_fba')\n",
    "import src.utils as utils\n",
    "import src.flux_utils as futils\n",
    "import src.flux_sample as fs\n",
    "import src.create_dataset as dataset\n",
    "import src.cf_io as cf_io\n",
    "import src.plotting as plotting\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/karim_data.CSV')\n",
    "df.drop(columns=['Area_1', 'Area_2', 'Conc_1', 'Conc_2'], inplace=True)\n",
    "n_experiments = df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, obj_col, cols = futils.read_data('../data/f2000', 'karim_karim_ecoli_cf_base.sbml_fluxes',\n",
    "                                                                    n_experiments, 'DM_btol_c', resamp=False, scale='flux_zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('../data/karim_stacked_fluxes', 'w')\n",
    "h5f.create_dataset('X_train', data=X_train, type=np.float32)\n",
    "h5f.create_dataset('X_test', data=X_test, type=np.float32)\n",
    "h5f.create_dataset('y_train', data=y_train)\n",
    "h5f.create_dataset('y_test', data=y_test)\n",
    "h5f.create_dataset('obj_col', data=obj_col)\n",
    "h5f.create_dataset('cols', data=cols)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = futils.scale_data(data=df['AVG.1'].values, scale_type='flux_zero', in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "froot = 'hand'\n",
    "txtl = False\n",
    "resamp = False\n",
    "fname = '../data/{0}{1}_{2}_fluxes'.format(froot, '_txtl' if txtl else '', 'stacked' if resamp else 'flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, obj_col, cols, y_vals_d = dataset.get_dataset(fname)\n",
    "y_vals = np.array(y_vals_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.recon_losses = []\n",
    "        self.kl_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_true = self.validation_data[0]\n",
    "        y_pred = self.model.predict(self.validation_data[0])\n",
    "        xent_loss = y_true.shape[-1] * np.mean(np.square(y_true - y_pred), axis=-1)\n",
    "        inputs = [K.learning_phase()] + self.model.inputs\n",
    "        zvar = K.function(inputs=inputs, outputs=[self.model.get_layer('z_log_var').output])\n",
    "        zmn = K.function(inputs=inputs, outputs=[self.model.get_layer('z_mean').output])\n",
    "        z_log_var = zvar([0, self.validation_data[0]])[0]\n",
    "        z_mean = zmn([0, self.validation_data[0]])[0]\n",
    "        kl_loss = - 0.5 * np.sum(1 + z_log_var - np.square(z_mean) - np.exp(z_log_var), axis=-1)\n",
    "        print \"Reconstruction loss: {0}\".format(np.mean(xent_loss))\n",
    "        print \"KL loss: {0}\".format(np.mean(kl_loss))\n",
    "        self.recon_losses.append(np.mean(xent_loss))\n",
    "        self.kl_losses.append(np.mean(kl_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [1024, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "epsilon_std = 1.0\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "def corr_loss(y_true, y_pred):\n",
    "    cent_pred = y_pred - K.mean(y_pred)\n",
    "    cent_tr = y_true - K.mean(y_true)\n",
    "\n",
    "    std_pred = K.std(y_pred)\n",
    "    std_tr = K.std(y_true)\n",
    "    return K.mean(cent_pred*cent_tr)/(std_pred*std_tr)\n",
    "\n",
    "def kl_loss(z_log_var, z_mean):\n",
    "    return - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "def build_vae(X_shape, n_experiments, targets, output_ind, batch_size=100):\n",
    "    encoded_dim1 = 1024\n",
    "    encoded_sz = 256\n",
    "    # Encoder network\n",
    "    x = Input(shape=(X_shape,))\n",
    "    #h = Dense(encoded_dim1, activation='relu')(x)\n",
    "    h = Dense(encoded_sz, activation='relu')(x)#h)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h)\n",
    "    \n",
    "    # Sample points from latent space\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    \n",
    "    # Decoder network\n",
    "    decoder_h = Dense(encoded_sz, activation='relu')\n",
    "    #decoder_h2 = Dense(encoded_dim1, activation='relu')\n",
    "    decoder_mean = Dense(X_shape, activation='tanh')\n",
    "    h_decoded = decoder_h(z)\n",
    "    #h_decoded2 = decoder_h2(h_decoded)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)#2)\n",
    "\n",
    "    # end-to-end autoencoder\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "    #vae = Model(x, [x_decoded_mean, x_decoded_mean])\n",
    "    #output_flux = x_decoded_mean[:, :, output_ind]\n",
    "    #experiment_loss = scipy.stats.spearmanr(targets, output_flux)\n",
    "    #experiment_loss_val = -1 * corr_loss(targets, output_flux)#streaming_pearson_correlation(output_flux, targets)\n",
    "    xent_loss = x.shape[-1].value * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "    kl_loss_val = kl_loss(z_log_var, z_mean)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss_val)# + experiment_loss_val\n",
    "    #print x.shape, x_decoded_mean.shape, z_mean.shape, z_log_var.shape\n",
    "    #print xent_loss.shape, kl_loss_val.shape, experiment_loss_val.shape, vae_loss.shape\n",
    "    #vae_loss = K.sum(vae_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='rmsprop')\n",
    "    #vae.compile(optimizer='rmsprop', loss=[lambda x, x_pred: gen_vae_loss(x, x_pred, z_log_var, z_mean),\n",
    "    #                                       lambda x, x_pred: corr_loss(targets, x_pred[:, :, output_ind])])\n",
    "    vae.summary()\n",
    "\n",
    "    # encoder, from inputs to latent space\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "    # generator, from latent space to reconstructed inputs\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    _h_decoded = decoder_h(decoder_input)\n",
    "    #_h_decoded2 = decoder_h2(_h_decoded)\n",
    "    _x_decoded_mean = decoder_mean(_h_decoded)#2)\n",
    "    generator = Model(decoder_input, _x_decoded_mean)\n",
    "    return vae, encoder, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%debug\n",
    "batch_size = 256\n",
    "n_epochs = 100\n",
    "X_shape, n_experiments = X_train.shape[1], df.shape[0]\n",
    "targets = tf.convert_to_tensor(y_vals, dtype=tf.float32)\n",
    "vae, encoder, generator = build_vae(X_shape, n_experiments, targets, obj_col, batch_size)\n",
    "es = EarlyStopping(patience=10)\n",
    "#lh = LossHistory()\n",
    "#with tf.Session(config=tf.ConfigProto(\n",
    "#                    intra_op_parallelism_threads=32)) as sess:\n",
    "#    K.set_session(sess)\n",
    "hist = vae.fit(X_train,\n",
    "        shuffle='batch',\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, None),\n",
    "        callbacks=[es])\n",
    "encoder.save('flat_encoder_dim=2_{0}_layers={1}_epochs={2}.h5'.format(scale, len(layer_sizes), n_epochs))\n",
    "generator.save('flat_generator_dim=2_{0}_layers={1}_epochs={2}.h5'.format(scale, len(layer_sizes), n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "vae2, encoder2, generator2 = build_vae(X_shape, n_experiments, targets, output_ind, batch_size)\n",
    "es = EarlyStopping(patience=10)\n",
    "lh2 = LossHistory()\n",
    "#with tf.Session(config=tf.ConfigProto(\n",
    "#                    intra_op_parallelism_threads=32)) as sess:\n",
    "#    K.set_session(sess)\n",
    "hist2 = vae2.fit(X_train,\n",
    "        shuffle=True,\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, None),\n",
    "        callbacks=[es, lh])\n",
    "encoder2.save('flat_encoder_dim=10_{0}.h5'.format(scale))\n",
    "generator2.save('flat_generator_dim=10_{0}.h5'.format(scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "use_corr = True\n",
    "froot = 'hand'\n",
    "txtl = True\n",
    "resamp = True\n",
    "layer_szs = [1024, 1024, 1024]\n",
    "flat = not resamp\n",
    "#encoder_epochs=200_batch=256_dimension=10_corr=True_scale=flux_zero_froot=hand_txtl=True_nlayers=3_resamp=True.h5\n",
    "#losses_epochs=200_batch=256_dimension=2_corr=True_scale=flux_zero_froot=hand_txtl=True_nlayers=3_resamp=True_lastlayer=1024.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cf_io.get_exp_data('manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, generator, X_test, y_test, obj_col, cols, y_vals_d, test_enc, test_dec = cf_io.get_test_data(\n",
    "    froot, txtl, resamp, latent_dim, layer_szs, use_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "use_corr = False\n",
    "froot = 'hand'\n",
    "txtl = True\n",
    "resamp = True\n",
    "layer_szs = [1024, 1024, 1024]\n",
    "flat = not resamp\n",
    "#encoder_epochs=200_batch=256_dimension=10_corr=True_scale=flux_zero_froot=hand_txtl=True_nlayers=3_resamp=True.h5\n",
    "#losses_epochs=200_batch=256_dimension=2_corr=True_scale=flux_zero_froot=hand_txtl=True_nlayers=3_resamp=True_lastlayer=1024.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_nc, generator_nc, X_test_nc, y_test_nc, obj_col_nc, cols_nc, y_vals_d_nc, test_enc_nc, test_dec_nc = cf_io.get_test_data(\n",
    "    froot, txtl, resamp, latent_dim, layer_szs, use_corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_corr = False\n",
    "resamp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_f, generator_f, X_test_f, y_test_f, obj_col_f, cols_f, y_vals_d_f, test_enc_f, test_dec_f = cf_io.get_test_data(\n",
    "    froot, txtl, resamp, latent_dim, layer_szs, use_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(8,8))\n",
    "plotting.plt_latent_space(encoded_data=test_enc, df=df, ax=axarr[0], legend=False)\n",
    "plotting.plt_latent_space(encoded_data=test_enc_nc, df=df, ax=axarr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test_encoded = test_enc\n",
    "df_sor = df.sort_values(by='nts')\n",
    "ind = df_sor.index\n",
    "cmap = cm.get_cmap('tab20', 17)#tab20\n",
    "#cmap = discrete_cmap(41, 'cubehelix')\n",
    "#for j in range(4):\n",
    "\n",
    "high_cols = (test_enc[:, 1] > 0)\n",
    "print sum(high_cols)\n",
    "#for i in range(latent_dim):\n",
    "    #for j in range(i + 1, latent_dim):\n",
    "i = 0\n",
    "j = 1\n",
    "low, high = 10, 1000#3000\n",
    "colors = np.array([[k] * (high - low) for k in range(17)]).T\n",
    "xmin, xmax = np.amin(x_test_encoded[low:high, ind, i]), np.amax(x_test_encoded[low:high, ind, i])\n",
    "ymin, ymax = np.amin(x_test_encoded[low:high, ind, j]), np.amax(x_test_encoded[low:high, ind, j])\n",
    "x_diff = (xmax - xmin) / 10.0\n",
    "y_diff = (ymax - ymin) / 10.0\n",
    "#for col in df.columns[4:]:\n",
    "plt.figure(figsize=(10, 10))\n",
    "sz = 60\n",
    "#for ix, idx in enumerate(ind):\n",
    "#    print idx\n",
    "#plt.scatter(x_test_encoded[low:high, idx, i], x_test_encoded[low:high, idx, j], c=[cmap.colors[ix]] * (high - low), \n",
    "#                cmap=cmap, s=sz,\n",
    "#                label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "#                            df_sor.loc[idx, 'mdx'], df_sor.loc[idx, 'pi'], df_sor.loc[idx, 'nts'], df_sor.loc[idx, 'k'])\n",
    "#                )#, norm=norm)#get_rct(df, col, y_test), cmap=cmap)\n",
    "sc = plt.scatter(x_test_encoded[low:high, ind, i], x_test_encoded[low:high, ind, j], c=colors, \n",
    "                cmap=cmap, s=sz)\n",
    "plt.xlim((xmin - x_diff, xmax + x_diff))\n",
    "plt.ylim((ymin - y_diff, ymax + y_diff))\n",
    "lp = lambda k: plt.plot([],color=sc.cmap(sc.norm(k)), ms=np.sqrt(sz), mec=\"none\",\n",
    "                        label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "                            df_sor.iloc[k, 0], df_sor.iloc[k, 1], df_sor.iloc[k, 2], df_sor.iloc[k, 3]), \n",
    "                        ls=\"\", marker=\"o\")[0]\n",
    "handles = [lp(k) for k in np.unique(range(17))]\n",
    "plt.legend(bbox_to_anchor=(1.25, 1.0))#handles=handles, \n",
    "plt.xlabel('z_1')\n",
    "plt.ylabel('z_2')\n",
    "plt.title('Plot of latent space of Corr-VAE')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = test_enc_f\n",
    "df_sor = df.sort_values(by='nts')\n",
    "ind = df_sor.index\n",
    "cmap = cm.get_cmap('tab20', 17)#tab20\n",
    "#cmap = discrete_cmap(41, 'cubehelix')\n",
    "#for j in range(4):\n",
    "\n",
    "high_cols = (test_enc[:, 1] > 0)\n",
    "print sum(high_cols)\n",
    "#for i in range(latent_dim):\n",
    "    #for j in range(i + 1, latent_dim):\n",
    "i = 0\n",
    "j = 1\n",
    "low, high = 10, 5000#3000\n",
    "#colors = np.array([[k] * (high - low) for k in range(17)]).T\n",
    "xmin, xmax = np.amin(x_test_encoded[low:high, i]), np.amax(x_test_encoded[low:high, i])\n",
    "ymin, ymax = np.amin(x_test_encoded[low:high, j]), np.amax(x_test_encoded[low:high, j])\n",
    "x_diff = (xmax - xmin) / 10.0\n",
    "y_diff = (ymax - ymin) / 10.0\n",
    "#for col in df.columns[4:]:\n",
    "plt.figure(figsize=(10, 10))\n",
    "sz = 60\n",
    "#for ix, idx in enumerate(ind):\n",
    "#    print idx\n",
    "#plt.scatter(x_test_encoded[low:high, idx, i], x_test_encoded[low:high, idx, j], c=[cmap.colors[ix]] * (high - low), \n",
    "#                cmap=cmap, s=sz,\n",
    "#                label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "#                            df_sor.loc[idx, 'mdx'], df_sor.loc[idx, 'pi'], df_sor.loc[idx, 'nts'], df_sor.loc[idx, 'k'])\n",
    "#                )#, norm=norm)#get_rct(df, col, y_test), cmap=cmap)\n",
    "sc = plt.scatter(x_test_encoded[low:high, i], x_test_encoded[low:high, j], c=y_test_f[low:high], \n",
    "                cmap=cmap, s=sz)\n",
    "plt.xlim((xmin - x_diff, xmax + x_diff))\n",
    "plt.ylim((ymin - y_diff, ymax + y_diff))\n",
    "lp = lambda k: plt.plot([],color=sc.cmap(sc.norm(k)), ms=np.sqrt(sz), mec=\"none\",\n",
    "                        label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "                            df_sor.iloc[k, 0], df_sor.iloc[k, 1], df_sor.iloc[k, 2], df_sor.iloc[k, 3]), \n",
    "                        ls=\"\", marker=\"o\")[0]\n",
    "handles = [lp(k) for k in np.unique(range(17))]\n",
    "#plt.legend(bbox_to_anchor=(1.25, 1.0))#handles=handles, \n",
    "plt.xlabel('z_1')\n",
    "plt.ylabel('z_2')\n",
    "plt.title('Plot of latent space of VAE')\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "colors = np.array([[k] * (high - low) for k in range(17)]).T\n",
    "sc = plt.scatter(x_test_encoded[low:high, :, i], x_test_encoded[low:high, :, j], c=colors, \n",
    "                cmap=cmap, s=sz)\n",
    "lp = lambda k: plt.plot([],color=sc.cmap(sc.norm(k)), ms=np.sqrt(sz), mec=\"none\",\n",
    "                        label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "                            df.loc[k, 'mdx'], df.loc[k, 'pi'], df.loc[k, 'nts'], df.loc[k, 'k']), \n",
    "                        ls=\"\", marker=\"o\")[0]\n",
    "handles = [lp(k) for k in np.unique(range(17))]\n",
    "plt.legend(bbox_to_anchor=(1.25, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "inds = np.sort(np.random.choice(X_test.shape[0], size=1000, replace=False))\n",
    "st_test = X_test[inds, : , :]\n",
    "fl_test = X_test[inds, : , :].reshape(st_test.shape[0] * st_test.shape[1], st_test.shape[2])\n",
    "fl_y = np.array([i for i in range(st_test.shape[1]) for j in range(st_test.shape[0])])\n",
    "st_enc = encoder.predict(st_test)\n",
    "fl_enc = encoder_f.predict(fl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "plt_inds = np.random.choice(fl_test.shape[0], size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_test_f[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_latent_space(encoded_data, df, ax, y_test=None, flat=False, dim_1=0, dim_2=1, samp_range=None,\n",
    "                     color_scheme='tab20', sz=60, legend=True, label='Dimension'):\n",
    "    df_sor = df.sort_values(by='nts')\n",
    "    n_experiments = df.shape[0]\n",
    "    ind = df_sor.index\n",
    "    cmap = cm.get_cmap(color_scheme, 17)\n",
    "\n",
    "    if samp_range is not None:\n",
    "        #low, high = samp_range\n",
    "        if type(samp_range) == int:\n",
    "            samp_range = range(samp_range)\n",
    "        encoded_data = encoded_data[samp_range]\n",
    "        if y_test is not None:\n",
    "            y_test = y_test[samp_range]\n",
    "    if flat:\n",
    "        colors = y_test\n",
    "        d_1 = encoded_data[:, dim_1]\n",
    "        d_2 = encoded_data[:, dim_2]\n",
    "    else:\n",
    "        colors = np.array([[k] * encoded_data.shape[0] for k in range(n_experiments)]).T\n",
    "        d_1 = encoded_data[:, ind, dim_1]\n",
    "        d_2 = encoded_data[:, ind, dim_2]\n",
    "\n",
    "    xmin, xmax = np.amin(d_1), np.amax(d_1)\n",
    "    ymin, ymax = np.amin(d_2), np.amax(d_2)\n",
    "    x_diff = (xmax - xmin) / 10.0\n",
    "    y_diff = (ymax - ymin) / 10.0    \n",
    "    print 'Plot d_1 vs d_2'\n",
    "    sc = ax.scatter(d_1, d_2, c=colors, cmap=cmap, s=sz)\n",
    "    ax.set_xlim((xmin - x_diff, xmax + x_diff))\n",
    "    ax.set_ylim((ymin - y_diff, ymax + y_diff))\n",
    "    if legend:\n",
    "        lp = lambda k: ax.plot([],color=sc.cmap(sc.norm(k)), ms=np.sqrt(sz), mec=\"none\",\n",
    "                                label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "                                    df_sor.iloc[k, 0], df_sor.iloc[k, 1], df_sor.iloc[k, 2], df_sor.iloc[k, 3]), \n",
    "                                ls=\"\", marker=\"o\")[0]\n",
    "        handles = [lp(k) for k in np.unique(range(17))]\n",
    "        ax.legend(bbox_to_anchor=(1.1, 1.0))#handles=handles, \n",
    "    ax.set_xlabel('{0} {1}'.format(label, dim_1))\n",
    "    ax.set_ylabel('{0} {1}'.format(label, dim_2))\n",
    "    \n",
    "axarr = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))[1]\n",
    "#plt_latent_space(fl_enc, df, axarr[0], flat=True, y_test=fl_y, samp_range=plt_inds, legend=False)\n",
    "#axarr[0].set_title('VAE latent space')\n",
    "plt_latent_space(st_enc, df, axarr, samp_range=range(1000), legend=True)\n",
    "axarr.set_title('Corr-VAE latent space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train2, orig_test, fl_y_train, fl_y_test, enc_train, enc_test= train_test_split(fl_test, fl_y, fl_enc, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train.shape, orig_test.shape, fl_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(orig_train, fl_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(orig_test, fl_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2.fit(enc_train, fl_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2.score(enc_test, fl_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "enc_pca = pca.fit_transform(fl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axarr = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))[1]\n",
    "plt_latent_space(enc_pca, df, axarr[0], flat=True, y_test=fl_y, samp_range=plt_inds, legend=False, label='Principal Component')\n",
    "axarr[0].set_title('PCA reduction')\n",
    "plt_latent_space(fl_enc, df, axarr[1], flat=True, y_test=fl_y, samp_range=plt_inds, legend=True)\n",
    "axarr[1].set_title('VAE latent space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = mpl.colorbar.ColorbarBase(ax2, cmap=cmap, norm=norm, spacing='proportional', ticks=bounds, boundaries=bounds, format='%1i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmaplist[0] = (.5,.5,.5,1.0)\n",
    "cmaplist[1] = (.5,.5,.5,1.0)\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0,40,41)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Glucose'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = test_enc[low:high, : , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh[0, 1 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc_2d[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc_2d = test_enc[low:high, : , :].reshape((high - low) * test_enc.shape[1], test_enc.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = tsne.fit_transform(test_enc_2d)\n",
    "#X_embedded2 = tsne.fit_transform(test_enc[low:high, : , 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.array(range(17) * lh.shape[0])\n",
    "col[:5]\n",
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fs.get_exp_data('hand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    print 'Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(row['mdx'], row['pi'], row['nts'], row['k'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sz = 50\n",
    "sc = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=col, s=sz)\n",
    "lp = lambda i: plt.plot([],color=sc.cmap(sc.norm(i)), ms=np.sqrt(sz), mec=\"none\",\n",
    "                        label='Sugar: {0}, Phosphate: {1}, NTs: {2}, Potassium: {3}'.format(\n",
    "                            df.loc[i, 'mdx'], df.loc[i, 'pi'], df.loc[i, 'nts'], df.loc[i, 'k']), \n",
    "                        ls=\"\", marker=\"o\")[0]\n",
    "handles = [lp(i) for i in np.unique(col)]\n",
    "plt.legend(handles=handles, bbox_to_anchor=(1.5, 1.0))\n",
    "plt.title('TSNE reduction of latent space')\n",
    "#plt.legend(range(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txtl = True\n",
    "rxn_amt = 5\n",
    "addl_amt = 1\n",
    "batch_size = 50\n",
    "n_batches = batch_size / rxn_amt\n",
    "model_f = '{0}_ecoli_cf_base{1}.sbml'.format('nls', '_txtl' if txtl else '')\n",
    "#model_f = '../models/ColiPruned.xml'\n",
    "#model_f = '../models/nls_ecoli_cf_varner.json.sbml'\n",
    "\n",
    "print 'Read in data'\n",
    "df = fs.get_exp_data(froot)\n",
    "#df.drop(columns=['Area_1', 'Area_2', 'Conc_1', 'Conc_2'], inplace=True)\n",
    "\n",
    "cfps_conc = pd.read_csv('../data/{0}_concs'.format('nls'), index_col='compound')\n",
    "if not froot == 'karim':\n",
    "    cfps_conc.drop('final_conc', inplace=True, axis=1)\n",
    "    nrg_mix = pd.read_csv('../data/energy_mix.csv', index_col='compound')\n",
    "else:\n",
    "    nrg_mix = None\n",
    "#print cfps_conc\n",
    "\n",
    "print 'Time to generate model specific conditions'\n",
    "model = cobra.io.read_sbml_model('../models/{0}'.format(model_f))\n",
    "print 'Model {0} read in'.format(model_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.objective.expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = []\n",
    "objs = []\n",
    "for idx, row in df.iterrows():\n",
    "    print idx\n",
    "    cfps_conc_tmp = cfps_conc.copy()\n",
    "    cfps_conc_tmp = fs.update_vals(cfps_conc_tmp, row, n_batches, nrg_mix=nrg_mix, replace=froot == 'karim')\n",
    "    tot_rxn_amt = rxn_amt + addl_amt\n",
    "    if froot == 'karim':\n",
    "        exp_concs = cfps_conc_tmp['final_conc']\n",
    "    else:\n",
    "        exp_concs = fs.conc_dilution(cfps_conc_tmp['start_conc'], (rxn_amt / 5.0) * cfps_conc_tmp['amt'], tot_rxn_amt)\n",
    "    model_i = fs.change_conc(model, exp_concs)\n",
    "    model_i.objective = model_i.reactions.PROTEIN_export_RFP\n",
    "    #print model_i.reactions.EX_mg2_c.bounds\n",
    "    #print model_i.reactions.EX_pi_c.bounds\n",
    "    sol = model_i.optimize()\n",
    "    fluxes.append(sol.fluxes)\n",
    "    objs.append(sol.objective_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i.reactions.BIOMASS_Ec_iJO1366_core_53p95M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(y_vals, objs)#fl[0, :, 2665])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_l = list(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = np.array(fluxes).reshape(1, 17, 2666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.predict(fl)\n",
    "dec = generator.predict(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec[0, :, obj_col.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(y_vals, dec[0, :, obj_col.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(y_vals, objs)#fl[0, :, 2665])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl[0, :, obj_col.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fluxes[1]#['DM_PROTEIN_RFP']\n",
    "s.index.get_loc('DM_PROTEIN_RFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index.get_loc('DM_PROTEIN_RFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(objs)\n",
    "res_df['Actual'] = df['OUT']\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
